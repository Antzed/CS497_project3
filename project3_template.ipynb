{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRIkKifMXV5f"
   },
   "source": [
    "# Project 3: Activity Detection with Machine Learning\n",
    "\n",
    "In this project, we will use a database containing activity data collected in Project 2.\n",
    "The main steps include:\n",
    " - **Loading** the database into a Pandas dataframe\n",
    " - **Extracting features** for machine learning\n",
    " - **Training** different models to find the best activity detection model\n",
    "\n",
    "Your assignment is to complete the analysis and submit the required files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1339,
     "status": "ok",
     "timestamp": 1715275355051,
     "user": {
      "displayName": "Blaine Rothrock",
      "userId": "10464371108573119789"
     },
     "user_tz": 240
    },
    "id": "nV8cQztYXWyK",
    "outputId": "42f8da83-70e2-4ac4-c920-e4d20695eec3"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive (Optional - for Colab users)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the working directory (update this path if needed)\n",
    "data_path = '/content/drive/MyDrive/mHealthCourse/project-3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBMrI42LXV5i"
   },
   "source": [
    "## Submission Requirements\n",
    "Your final submission should be a **single compressed file** containing:\n",
    " - **Completed Jupyter Notebook** (this file, with all outputs and analysis)\n",
    " - **PDF Report** with the required write-ups and explanations\n",
    " - **C Header File (`.h`)** containing the best-trained model ported to C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7ZjyxDfXV5i"
   },
   "source": [
    "## Setp 1. Load the Activity Database\n",
    "Ensure that the dataset file is located in the correct directory, or update the file path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 3878,
     "status": "ok",
     "timestamp": 1715275409925,
     "user": {
      "displayName": "Blaine Rothrock",
      "userId": "10464371108573119789"
     },
     "user_tz": 240
    },
    "id": "FGhnJqxPXV5i",
    "outputId": "c5641963-a04d-4e86-ee17-92b32913bb27"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the dataset (update if necessary)\n",
    "db_path = os.path.join(data_path, 'dataset_spring_2024.csv') \n",
    "\n",
    "# Load the dataset into a Pandas dataframe\n",
    "df = pd.read_csv(db_path, dtype={'label': 'str', 'participant': 'str'})\n",
    "\n",
    "# Remove unnecessary columns (e.g., timestamp if not needed)\n",
    "df = df.drop(columns=['time_ms'])\n",
    "\n",
    "# Display basic dataset information\n",
    "df.info()\n",
    "\n",
    "# Display the first 10 rows to inspect the dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "executionInfo": {
     "elapsed": 3957,
     "status": "ok",
     "timestamp": 1715275437416,
     "user": {
      "displayName": "Blaine Rothrock",
      "userId": "10464371108573119789"
     },
     "user_tz": 240
    },
    "id": "rtmwb_WqXV5k",
    "outputId": "d299c971-9812-4551-f145-052cb5236260"
   },
   "outputs": [],
   "source": [
    "# include the dataset from 2023\n",
    "db_path = os.path.join(data_path, 'dataset_winter_2023.csv')\n",
    "df_2023 = pd.read_csv(db_path)\n",
    "\n",
    "# clean the data to match this year's dataset\n",
    "df_2023['label'] = df_2023['label'].str.lower().str.strip()\n",
    "df_2023['label'] = df_2023['label'].str.replace('sitting/working with a computer', 'sitting')\n",
    "df_2023['label'] = df_2023['label'].str.replace('sitting/working\\xa0with a computer', 'sitting')\n",
    "print(df_2023.label.unique())\n",
    "\n",
    "df_2023['participant'] = df_2023['participant'].astype(str)\n",
    "\n",
    "# add 100 each participant id to separate\n",
    "def _reformat_participant_id(id_str):\n",
    "    id = int(id_str.lower().split('p')[-1])\n",
    "    id += 100\n",
    "    return f'P{id}'\n",
    "df_2023['participant'] = df_2023['participant'].apply(_reformat_participant_id)\n",
    "\n",
    "df_2023 = df_2023.drop(columns=['time'])\n",
    "\n",
    "df_2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1715275443914,
     "user": {
      "displayName": "Blaine Rothrock",
      "userId": "10464371108573119789"
     },
     "user_tz": 240
    },
    "id": "rUN3MaNGXV5k",
    "outputId": "c5f489f1-df87-48f0-d69f-7476f8cdbc22"
   },
   "outputs": [],
   "source": [
    "# merge the database\n",
    "df = pd.concat([df, df_2023], ignore_index=True)\n",
    "\n",
    "# clean up\n",
    "del df_2023\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fofpBup8XV5k"
   },
   "source": [
    "## Setp 2. Extract Features\n",
    "\n",
    "Here we will select a window size and compute aggregations on the dataset. The following line of code will create a new dataframe which will compute aggregate statistics across each participant, label, and window size.\n",
    "\n",
    "**Note**: this will take some time to compute, especially on a Google Colab instance. The more complex the aggregation calculations, the longer it will take.\n",
    "\n",
    "\n",
    "### <span style=\"color:red\">Task 2.1</span>\n",
    "<span style=\"color:red\">Add at least 4 additional features to the feature set. We have provided `mean` and `std` (standard deviation)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 26247,
     "status": "ok",
     "timestamp": 1715275473290,
     "user": {
      "displayName": "Blaine Rothrock",
      "userId": "10464371108573119789"
     },
     "user_tz": 240
    },
    "id": "YN5jm0a7XV5k",
    "outputId": "200ca4bf-15c4-4f1e-8958-624ba4e7fa7c"
   },
   "outputs": [],
   "source": [
    "# Define window size for feature extraction\n",
    "window_size = 100 # Corresponds to approximately 1 second of data\n",
    "\n",
    "############### edit code below ############### \n",
    "df_grouped = df.groupby(['participant', 'label']).rolling(window=window_size).agg({\n",
    "    # 'time_ms': ['sum'],\n",
    "    'accel_x': ['mean', 'std'],\n",
    "    'accel_y': ['mean', 'std'],\n",
    "    'accel_z': ['mean', 'std'],\n",
    "    'gyr_x': ['mean', 'std'],\n",
    "    'gyr_y': ['mean', 'std'],\n",
    "    'gyr_z': ['mean', 'std']\n",
    "}).reset_index().dropna()\n",
    "\n",
    "# flatten column names so there are is no column levels\n",
    "df_grouped.columns = ['_'.join(col).strip() for col in df_grouped.columns.values]\n",
    "\n",
    "# clean up columns\n",
    "df_grouped.rename(columns={'participant_': 'participant', 'label_': 'label'}, inplace=True)\n",
    "df_grouped.drop(columns=['level_2_'], inplace=True)\n",
    "\n",
    "# # optional - save the database to avoid re-running the above code\n",
    "# df_group_file_path = f'project2_class_dataset_grouped_w{window_size}.csv'\n",
    "# df_grouped.to_csv(df_group_file_path, index=False)\n",
    "\n",
    "# then read the csv file\n",
    "# df_grouped = pd.read_csv(df_group_file_path)\n",
    "\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qgP3R5sXV5l"
   },
   "source": [
    "## Setp 3. Feature Selection\n",
    "\n",
    "Here we will find the *best* features to use in our model. This can be done by using a variety of techniques, including *forward selection*, *backward selection*, *L1 regularization*, or *Random Forest Importance*. See [feature selection in Python](https://scikit-learn.org/stable/modules/feature_selection.html) for more information.\n",
    "\n",
    "We provide two methods for features selection, *Univariate Feature Selection* and *Recursive Feature Elimination (RFE)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715275473290,
     "user": {
      "displayName": "Blaine Rothrock",
      "userId": "10464371108573119789"
     },
     "user_tz": 240
    },
    "id": "wUFIQSFAXV5l"
   },
   "outputs": [],
   "source": [
    "X = df_grouped.drop(columns=['participant', 'label']) # all columns except grouped columns\n",
    "y = df_grouped['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcsWy20qXV5l"
   },
   "source": [
    "### 3.1 Univariate Feature Selection\n",
    "\n",
    "### <span style=\"color:red\">Task 3.1</span>\n",
    "<span style=\"color:red\">Explain the process of univariate feature selection (~1 paragraph, what is the purpose of this method? How does it work?). Which feature have the most importance according to this method?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 4600,
     "status": "ok",
     "timestamp": 1715275477889,
     "user": {
      "displayName": "Blaine Rothrock",
      "userId": "10464371108573119789"
     },
     "user_tz": 240
    },
    "id": "PJNwyrZTXV5l",
    "outputId": "f1fdf207-04b1-4fcb-8825-1d091220620c"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Perform univariate feature selection\n",
    "k = X.columns.size # select all features\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "features_selected = selector.get_support(indices=True)\n",
    "selected_feature_names = X.columns[features_selected]\n",
    "\n",
    "# print names and f_scores of selected features\n",
    "selected_features = pd.DataFrame({'feature': selected_feature_names, 'f_score': selector.scores_[features_selected]})\n",
    "selected_features = selected_features.sort_values(by='f_score', ascending=False)\n",
    "selected_features.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLT806NOXV5l"
   },
   "source": [
    "### 3.2 Recursive Feature Elimination (RFE)\n",
    "\n",
    "Here we use the method of RFE to select the best features. Different from the univariate feature selection, RFE selects features by recursively considering smaller and smaller sets of features. We choose how we evaluate the importance of a feature by setting the parameter `estimator`. In this case, we use a `RandomForestClassifier` to evaluate the importance of a feature.\n",
    "\n",
    "**Note**: this will take some time to run. (ex: 5.5mins on M2 Macbook Pro)\n",
    "\n",
    "### <span style=\"color:red\">Task 3.2</span>\n",
    "<span style=\"color:red\">Explain the process of recursive feature elimination (~1 paragraph, what is the purpose of this method? How does it work?). Which feature have the most importance according to this method?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "T8J1Az05XV5m"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=5, # the number of trees in the forest\n",
    "    random_state=42, # for reproducibility\n",
    "    max_depth=5 # the maximum depth of the tree\n",
    ")\n",
    "rfe = RFE(estimator=model, n_features_to_select=4, step=1)\n",
    "\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "\n",
    "selected_features_rfe = X.columns[rfe.support_]\n",
    "\n",
    "print(\"Features selected by RFE:\", selected_features_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwnYjqjSXV5m"
   },
   "source": [
    "### <span style=\"color:red\">Task 3.3: Additional Feature Selection Method</span>\n",
    "\n",
    "<span style=\"color:red\">Please implement an additional feature selection method of your choice. You can use any feature selection method from the [scikit-learn library](https://scikit-learn.org/stable/modules/feature_selection.html), or any others. In your report, writing a short description of the method and the results, similar to above but include **why** you selected this method.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dkqY1mBXXV5m"
   },
   "outputs": [],
   "source": [
    "## implement additional feature selection method here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE55CgtZXV5m"
   },
   "source": [
    "### Task 3.4: Feature Selection\n",
    "\n",
    "Choose the best features from the methods above and create a new dataframe with only those features. In your report, note which features you selected, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lfhhQ82OXV5m"
   },
   "outputs": [],
   "source": [
    "# example features, you should choose your own.\n",
    "selected_features = ['accel_x_std', 'accel_y_std', 'accel_z_std', 'gyr_x_std', 'gyr_y_std', 'gyr_z_std']\n",
    "df_selected_features = df_grouped[['participant', 'label'] + selected_features]\n",
    "\n",
    "df_selected_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43AEcCsbXV5m"
   },
   "source": [
    "## Setp 4. Model Training & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU_coIVeXV5m"
   },
   "source": [
    "### 4.1 Train/Test Split by Percentage\n",
    "\n",
    "We divide our dataset into a training set and a test set. We will train the model on the training set and evaluate the model on the test set. We split with a percentage, where we use a randomly distribution of the percentage of the data for the training and testing - 33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Gu2A7R_yXV5m"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.33 # percentage of data for testing\n",
    "\n",
    "X = df_selected_features[selected_features]\n",
    "Y = df_selected_features['label']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BE7Xe-u2XV5m"
   },
   "source": [
    "### 4.2 Model Training\n",
    "\n",
    "Here we will train a series of models and evaluate them. We have provided two models: `Decision Tree Classifier`, and `GradientBoostingClassifier`.\n",
    "\n",
    "### <span style=\"color:red\">Task 4.2</span>\n",
    "<span style=\"color:red\">Please train 4 additional classifiers model. For each, including the ones we include a brief description (~1 paragraph). For the models you choose, explain why you chose it. Please limit you selection to machine learning models, we will try out deep learning models in the next project. You are free to use any models from the [scikit-learn library](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning), you may also use other as long as they are not deep learning models (e.g., multi-layer neural networks).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0tGb2XnUXV5m"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train multiple models and compare performance\n",
    "############### edit code below ############### \n",
    "models = []\n",
    "models.append(DecisionTreeClassifier(random_state=0, max_depth=5))\n",
    "models.append(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NRA1qSqZXV5m"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "############### edit code below ############### \n",
    "for model in models:\n",
    "    print('training: ', model.__class__.__name__)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    print(' - accuracy: ', accuracy)\n",
    "    results.append(\n",
    "        {\n",
    "            'name': model.__class__.__name__,\n",
    "            'accuracy': sklearn.metrics.accuracy_score(y_test, y_pred),\n",
    "            'confusion_matrix': sklearn.metrics.confusion_matrix(y_test, y_pred),\n",
    "            'classification_report': sklearn.metrics.classification_report(y_test, y_pred)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2AWSe2OXV5m"
   },
   "source": [
    "### <span style=\"color:red\">Task 4.3: Model Reporting</span>\n",
    "<span style=\"color:red\">Report the results of each model, which one performed the best? Please print the model results below, but include a short write-up in your report.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zktFqKw1XV5n"
   },
   "outputs": [],
   "source": [
    "# model results\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YPlS9eCXV5n"
   },
   "source": [
    "## 5. LOSO (Leave-One-Subject-Out) Experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjWPYEuIXV5n"
   },
   "source": [
    "We have XX participants in our dataset. In this experiment we will train our best model above, but instead of randomly splitting the data, we will use a Leave-One-Subject-Out (LOSO) method. This means we will train on all participants except one, and then evaluate the model on the left out participant. We will repeat this process for all participants and then average the results. We will then compare the results with the previous model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXFitrN8XV5n"
   },
   "source": [
    "### <span style=\"color:red\">Task 5.1: LOSO</span>\n",
    "<span style=\"color:red\">Create the variables `X_test`, `y_test`, `X_train`, `y_train` for the LOSO experiment.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxvX17LFXV5n"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "num_participants = df_selected_features['participant'].unique().size\n",
    "test_participant = df_selected_features['participant'].unique()[random.randint(0, num_participants)]\n",
    "\n",
    "# implement code here to create X_train, y_train, X_test, y_test for LOSO\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2_GoqR5XV5n"
   },
   "source": [
    "### <span style=\"color:red\">Task 5.2: Train Model w/ LOSO</span>\n",
    "<span style=\"color:red\">Train the best model with the LOSO method. report the results, and compare with the previous model evaluation. Write a short explanation of your observations. Why do you think it perform better or worse?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGDM9-hGXV5n"
   },
   "outputs": [],
   "source": [
    "# train and report results\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvVdjxBJXV5n"
   },
   "source": [
    "### <span style=\"color:red\">Task 5.3 Cross Validation</span>\n",
    "<span style=\"color:red\">In the interest of time, we will not implement cross-validation. But please include a short explanation of how you would implement cross-validation, and why it is important. (~1 paragraph)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAf1fyO5XV5n"
   },
   "source": [
    "## 6. Port Model\n",
    "\n",
    "We will now port the model to C, for use in Arduino. Please include the C file in your submission, but we will not run it on the embedded device for this assignment. In the next assignment, we will run the model on the Arduino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrKF1HwWXV5n"
   },
   "source": [
    "### 6.1 install `micromlgen`\n",
    "\n",
    "[micromlgen](https://github.com/eloquentarduino/micromlgen) is a opensource project which will generate C code from your sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRejjKgwXV5n",
    "outputId": "e22fb592-19b8-437e-e56a-b7f23f39de3c"
   },
   "outputs": [],
   "source": [
    "pip install micromlgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4F_vnV-SXV5n"
   },
   "source": [
    "### <span style=\"color:red\">Task 6.2: Port Best Model and save</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwpSbvO1XV5n",
    "outputId": "ea947792-ac9e-4d79-cd75-b76eef2aa0e2"
   },
   "outputs": [],
   "source": [
    "from micromlgen import port\n",
    "\n",
    "# Select the best performing model (e.g., Gradient Boosting)\n",
    "c_code = port(models[0])\n",
    "\n",
    "print(c_code)\n",
    "\n",
    "# save/port the model to a directory\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZ5M3LutXV5s"
   },
   "source": [
    "### <span style=\"color:red\">Task 6.3: Model Review</span>\n",
    "<span style=\"color:red\">Take a look at the C code, what do you notice? Do you think the model will run on our microcontrollers? Why or why not? Please include a brief write-up in your report.</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
